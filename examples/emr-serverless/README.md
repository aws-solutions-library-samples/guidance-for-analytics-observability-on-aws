
# EMR Serverless example with AWS Observability

This is an EMR Serverless example running a TPCDS benchmark that can be configured to send logs and metrics to Opensearch ingestion pipelines. 
The job will be run every 2 hours by default.

## Pre-requisites

* Customize the `log4j2.properties` with the endpoint URL of the Opensearch ingestion for logs. 
The endpoint is generated by the CDK stack available in `infra` folder. The information is only available via the console or CLI (not in CDK yet)

* Build the collector library in `collector` and copy the jar file in `docker` folder so it's ready to be packaged in the EMR Serverless custom image
  * Run in `<ROOT>/collector`
    ```
    sbt run assembly
    ```
  * Copy the jar file
    ```
    cp <ROOT>/collector/target/scala-2.12/spark-observability-collector-assembly.jar <ROOT>/examples/emr-serverless/docker
    ```

## Deploy the EMR Serverless application

Create a virtualenv on MacOS and Linux:

```
$ python3 -m venv .venv
```

After the init process completes and the virtualenv is created, you can use the following
step to activate your virtualenv.

```
$ source .venv/bin/activate
```

If you are a Windows platform, you would activate the virtualenv like this:

```
% .venv\Scripts\activate.bat
```

Once the virtualenv is activated, you can install the required dependencies.

```
$ pip install -r requirements.txt
```

At this point deploy the resources with the URL of the Opensearch ingestion for metrics and the IAM policy ARN of the collector from the `infra` stack 

```
$ cdk deploy -c metrics_ingestion_url=<METRICS_URL> -c collector_policy_arn=<INGESTION_ARN>
```

## Manually trigger the TPCS DS benchmark

From the console, run the Step Function deployed by the CDK application